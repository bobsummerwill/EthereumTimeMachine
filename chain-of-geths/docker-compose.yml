services:
  # Modern top node: follows current mainnet and is paired with a consensus client (Lighthouse below).
  # This is the head-syncing node in the chain.
  geth-v1-16-7:
    image: ethereum/client-go:v1.16.7
    container_name: geth-v1-16-7
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
    entrypoint: ["/bin/sh", "/watchdog/geth-self-watchdog.sh"]
    environment:
      # Head node: target is derived from `eth_syncing` (no fixed target).
      # Keep a slower cadence by default; legacy nodes override this.
      SAMPLE_INTERVAL_SECONDS: ${WATCHDOG_SAMPLE_INTERVAL_SECONDS:-600}
    command: |
      --config /data/config.toml
      --datadir /data
      --cache 4096
      --nodekey /data/geth/nodekey
      --http
      --http.addr 0.0.0.0
      --http.vhosts *
      --http.api eth,net,web3
      --authrpc.addr 0.0.0.0
      --authrpc.port 8551
      --authrpc.vhosts *
      --authrpc.jwtsecret /data/geth/jwtsecret
      --syncmode ${GETH_V1_16_7_SYNCMODE:-full}
      --networkid 1
      --port 30306
    ports:
      - "8545:8545"
      - "30306:30306/tcp"
      - "30306:30306/udp"
    volumes:
      - ./generated-files/data/v1.16.7:/data
      - ./monitoring/self-watchdog:/watchdog:ro
    networks:
      ethereum:
        ipv4_address: 172.20.0.18

  # Protocol bridge node (eth/66-68 compatibility).
  #
  # In the *offline seeding* workflow, this node is NOT intended to follow the post-Merge head.
  # Instead, we populate its datadir via export/import from the modern node (`geth-v1-16-7`):
  #   1) Export an RLP block range 0..CUTOFF_BLOCK (see `seed-v1.11.6-when-ready.sh`).
  #   2) Import that RLP into this node's datadir (`geth import`).
  #
  # Once seeded, `geth-v1-11-6` serves as a *protocol bridge* down to `geth-v1-10-8` (and below)
  # so older clients can access the historical chain range without needing to speak to modern mainnet.
  geth-v1-11-6:
    image: ethereumtimemachine/geth:v1.11.6
    container_name: geth-v1-11-6
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/watchdog/geth-self-watchdog.sh"]
    environment:
      # This node is intentionally pinned to the historical cutoff; treat that as its target.
      FIXED_TARGET_BLOCK: "1919999"
      SAMPLE_INTERVAL_SECONDS: ${LEGACY_WATCHDOG_SAMPLE_INTERVAL_SECONDS:-300}
    command: |
      --config /data/config.toml
      --datadir /data
      --cache 2048
      --nodekey /data/geth/nodekey
      --http
      --http.addr 0.0.0.0
      --http.vhosts *
      --http.api eth,net,web3
      --syncmode full
      --networkid 1
      --port 30308
      --nodiscover
    ports:
      - "8546:8545"
      - "30308:30308/tcp"
      - "30308:30308/udp"
    volumes:
      - ./generated-files/data/v1.11.6:/data
      - ./monitoring/self-watchdog:/watchdog:ro
    networks:
      ethereum:
        ipv4_address: 172.20.0.15

  # Bridge node: eth/66<->eth/65 compatibility.
  # Geth v1.10.8 supports eth/65, eth/66.
  geth-v1-10-8:
    image: ethereumtimemachine/geth:v1.10.8
    container_name: geth-v1-10-8
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/watchdog/geth-self-watchdog.sh"]
    environment:
      # Downstream nodes should all converge to the same cutoff height.
      FIXED_TARGET_BLOCK: "1919999"
      SAMPLE_INTERVAL_SECONDS: ${LEGACY_WATCHDOG_SAMPLE_INTERVAL_SECONDS:-300}
    # Troubleshooting: disable snapshots to prevent v1.10.8 from falling into fast/snapshot recovery,
    # which can cause it to drop the offline-seeded upstream peer as "unsynced".
    # Also bump verbosity temporarily to capture peer/drop reasons.
    command: |
      --datadir /data
      --nodekey /data/nodekey
      --cache 2048
      --snapshot=false
      --http
      --http.addr 0.0.0.0
      --http.vhosts *
      --http.api eth,net,web3
      --syncmode full
      --networkid 1
      --port 30309
      --nodiscover
    ports:
      - "8551:8545"
      - "30309:30309/tcp"
      - "30309:30309/udp"
    volumes:
      - ./generated-files/data/v1.10.8:/data
      - ./monitoring/self-watchdog:/watchdog:ro
    depends_on:
      - geth-v1-11-6
    networks:
      ethereum:
        ipv4_address: 172.20.0.16

  # Bridge node: eth/65<->eth/63 compatibility.
  # Geth v1.9.25 supports eth/63, eth/64, eth/65.
  geth-v1-9-25:
    image: ethereumtimemachine/geth:v1.9.25
    container_name: geth-v1-9-25
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/watchdog/geth-self-watchdog.sh"]
    environment:
      FIXED_TARGET_BLOCK: "1919999"
      SAMPLE_INTERVAL_SECONDS: ${LEGACY_WATCHDOG_SAMPLE_INTERVAL_SECONDS:-300}
    command: |
      --datadir /data
      --nodekey /data/nodekey
      --cache 2048
      --rpc
      --rpcaddr 0.0.0.0
      --rpcvhosts *
      --rpcapi eth,net,web3
      --networkid 1
      --syncmode full
      --port 30310
      --nodiscover
      --snapshot=false
      --nousb
    ports:
      - "8552:8545"
      - "30310:30310/tcp"
      - "30310:30310/udp"
    volumes:
      - ./generated-files/data/v1.9.25:/data
      - ./monitoring/self-watchdog:/watchdog:ro
    depends_on:
      - geth-v1-10-8
    networks:
      ethereum:
        ipv4_address: 172.20.0.17

  # Bridge node: eth/63<->Frontier-era compatibility.
  # Geth v1.3.6 supports eth/61-63 and can still talk to v1.9.25.
  # This exists because v1.0.2 is too old to speak directly to v1.9.25.
  geth-v1-3-6:
    image: ethereumtimemachine/geth:v1.3.6
    container_name: geth-v1-3-6
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/watchdog/geth-self-watchdog.sh"]
    environment:
      FIXED_TARGET_BLOCK: "1919999"
      SAMPLE_INTERVAL_SECONDS: ${LEGACY_WATCHDOG_SAMPLE_INTERVAL_SECONDS:-300}
    # v1.3.x uses `--fast` (bool) to enable fast sync; explicitly disable to force full sync.
    command: |
      --datadir /data
      --nodekey /data/nodekey
      --cache 4096
      --fast=false
      --rpc
      --rpcaddr 0.0.0.0
      --rpcapi eth,net,web3
      --networkid 1
      --port 30311
      --nodiscover
    ports:
      - "8553:8545"
      - "30311:30311/tcp"
      - "30311:30311/udp"
    volumes:
      - ./generated-files/data/v1.3.6:/data
      - ./monitoring/self-watchdog:/watchdog:ro
    depends_on:
      - geth-v1-9-25
    networks:
      ethereum:
        ipv4_address: 172.20.0.13

  # Frontier-era tail nodes (eth/60 compatibility).
  # These sync from the next node up (v1.3.6) via static peering.
  geth-v1-0-2:
    image: ethereumtimemachine/geth:v1.0.2
    container_name: geth-v1-0-2
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/watchdog/geth-self-watchdog.sh"]
    environment:
      FIXED_TARGET_BLOCK: "1149999"
      SAMPLE_INTERVAL_SECONDS: ${V1_0_3_WATCHDOG_SAMPLE_INTERVAL_SECONDS:-120}
      STALL_REQUIRED_SAMPLES: "1"
      REQUIRE_PEERS_FOR_RESTART: "0"
    command: |
      --datadir /data
      --nodekey /data/nodekey
      --cache 2048
      --rpc
      --rpcaddr 0.0.0.0
      --rpcapi eth,net,web3
      --networkid 1
      --port 30312
      --nodiscover
    ports:
      - "8554:8545"
      - "30312:30312/tcp"
      - "30312:30312/udp"
    volumes:
      - ./generated-files/data/v1.0.2:/data
      - ./monitoring/self-watchdog:/watchdog:ro
    depends_on:
      - geth-v1-3-6
    networks:
      ethereum:
        ipv4_address: 172.20.0.12

  # Consensus client (beacon node) for the *modern feeder* execution node.
  # We keep this single CL instance so the modern EL can progress on post-Merge mainnet
  # and continue serving historical blocks to older nodes.
  lighthouse-v8-0-1:
    image: sigp/lighthouse:v8.0.1
    container_name: lighthouse-v8-0-1
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
    command: |
      lighthouse beacon_node
      --datadir /data
      --execution-endpoint http://geth-v1-16-7:8551
      --execution-jwt /jwt/jwtsecret
      --checkpoint-sync-url https://mainnet.checkpoint.sigp.io
      --http
      --http-address 0.0.0.0
      --http-port 5052
      --metrics
      --metrics-address 0.0.0.0
      --metrics-port 8080
      --port 9000
      --discovery-port 9000
      --quic-port 9001
    ports:
      - "8080:8080"
      - "9000:9000/tcp"
      - "9000:9000/udp"
      - "9001:9001/udp"
    volumes:
      - lighthouse-v8-0-1-data:/data
      - ./generated-files/data/v1.16.7/geth/jwtsecret:/jwt/jwtsecret:ro
    networks:
      - ethereum

  # --- Monitoring (Prometheus + Grafana) ---
  # This is intentionally JSON-RPC based (not geth --metrics) so it works across older versions.

  geth-exporter:
    build:
      context: ./monitoring/exporter
    container_name: geth-exporter
    environment:
      # First node is treated as the “top” reference for lag metrics.
      NODE_URLS: >-
        Geth v1.16.7=http://geth-v1-16-7:8545,
        Geth v1.11.6=http://geth-v1-11-6:8545,
        Geth v1.10.8=http://geth-v1-10-8:8545,
        Geth v1.9.25=http://geth-v1-9-25:8545,
        Geth v1.3.6=http://geth-v1-3-6:8545,
        Geth v1.0.2=http://geth-v1-0-2:8545
      # Used to add a Lighthouse row in the same “Sync progress” table.
      LIGHTHOUSE_API_URL: http://lighthouse-v8-0-1:5052
      # Stable label for the Lighthouse row (emit from startup even if the API is still booting).
      LIGHTHOUSE_DISPLAY_NAME: Lighthouse v8.0.1
      # Used for stage checklist (best-effort backfill detection).
      LIGHTHOUSE_METRICS_URL: http://lighthouse-v8-0-1:8080
      # Used for stage checklist (export/import phases) by reading files under the host ./generated-files bind.
      HOST_OUTPUT_DIR: /host_output
      CUTOFF_BLOCK: "1919999"
      V1_0_3_TARGET_BLOCK: "1149999"
      # Applies to all Geth v1.0.x nodes (currently: v1.0.2). Kept separate from the global cutoff.
      V1_0_X_TARGET_BLOCK: "1149999"
      POLL_INTERVAL_SECONDS: "10"
      # Optional: hide specific node labels from the progress table (Grafana “Stage progress” / Sync-UI).
      # Remote deploy uses this to hide the offline-seeded bridge node row (it is represented by the Import phase row).
      HIDE_PROGRESS_NODES_REGEX: ${HIDE_PROGRESS_NODES_REGEX:-}
    volumes:
      - ./generated-files:/host_output:ro
    ports:
      - "9100:9100"
    networks:
      - ethereum


  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    depends_on:
      - geth-exporter
    networks:
      - ethereum

  # Minimal web UI that queries Prometheus and renders a “Sync progress” table.
  sync-ui:
    build:
      context: ./monitoring/sync-ui
    container_name: sync-ui
    environment:
      PROMETHEUS_URL: http://prometheus:9090
      PORT: "8088"
      V1_0_3_TARGET_BLOCK: "1149999"
      V1_0_X_TARGET_BLOCK: "1149999"
    ports:
      - "8088:8088"
    depends_on:
      - prometheus
    networks:
      - ethereum

  # Slideshow UI: cycles between multiple views (sync progress, charts) every 10 seconds.
  slideshow-ui:
    build:
      context: ./monitoring/slideshow-ui
    container_name: slideshow-ui
    environment:
      SYNC_UI_URL: http://sync-ui:8088
      CHARTS_DIR: /charts
      PORT: "8089"
      CYCLE_SECONDS: "10"
    ports:
      - "8089:8089"
    volumes:
      - ./generated-files/charts:/charts:ro
    depends_on:
      - sync-ui
    networks:
      - ethereum

  grafana:
    image: grafana/grafana:11.3.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      # For quick local use; change for any exposed deployment.
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - ethereum

networks:
  ethereum:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  prometheus-data:
  grafana-data:
  lighthouse-v8-0-1-data:
